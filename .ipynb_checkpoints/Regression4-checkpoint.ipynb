{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression Analysis using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook will cover some of the basic ways to perform regression analysis on a dataframe to predict a continuous variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tools and libraries used: \n",
    "  \n",
    " -Python\n",
    "  \n",
    " -Jupyter notebook\n",
    "\n",
    " -Pandas\n",
    " \n",
    " -Numpy\n",
    " \n",
    " -Plotly\n",
    " \n",
    " -Scikit-learn (Used for sample data and regression algorithims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Regression analysis?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression analysis is a statistical process for estimating the relationships among variables. It includes many techniques for modeling and analyzing several variables, when the focus is on the relationship between a dependent variable and one or more independent variables (or 'predictors') - Wikipedia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression is used to fit a straight line or 'trendline' to two variables X and Y that are dependant on each other"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook I will be using a sample dataset that contains Boston House Pricing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started the following libraries need to be imported. I will not import all the libraries used in this notebook here to avoid confusion. Usually though it is standard practice to import all the libraries at the top of your notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##import house price data from sklearn datasets\n",
    "boston = datasets.load_boston()\n",
    "#the data is imported as a json object by default\n",
    "#to create a pandas dataframe from it we need to do the following\n",
    "\n",
    "names = boston.feature_names #used to assign names to columns\n",
    "\n",
    "bos = pd.DataFrame(boston.data) #import data into dataframe\n",
    "bos.columns = names #assign column names \n",
    "bos.head() #display first five rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = boston.target #this is price variable what we will be trying to predict\n",
    "bos['PRICE'] = target #create new column with target\n",
    "bos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boston House Prices dataset\n",
      "===========================\n",
      "\n",
      "Notes\n",
      "------\n",
      "Data Set Characteristics:  \n",
      "\n",
      "    :Number of Instances: 506 \n",
      "\n",
      "    :Number of Attributes: 13 numeric/categorical predictive\n",
      "    \n",
      "    :Median Value (attribute 14) is usually the target\n",
      "\n",
      "    :Attribute Information (in order):\n",
      "        - CRIM     per capita crime rate by town\n",
      "        - ZN       proportion of residential land zoned for lots over 25,000 sq.ft.\n",
      "        - INDUS    proportion of non-retail business acres per town\n",
      "        - CHAS     Charles River dummy variable (= 1 if tract bounds river; 0 otherwise)\n",
      "        - NOX      nitric oxides concentration (parts per 10 million)\n",
      "        - RM       average number of rooms per dwelling\n",
      "        - AGE      proportion of owner-occupied units built prior to 1940\n",
      "        - DIS      weighted distances to five Boston employment centres\n",
      "        - RAD      index of accessibility to radial highways\n",
      "        - TAX      full-value property-tax rate per $10,000\n",
      "        - PTRATIO  pupil-teacher ratio by town\n",
      "        - B        1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
      "        - LSTAT    % lower status of the population\n",
      "        - MEDV     Median value of owner-occupied homes in $1000's\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Creator: Harrison, D. and Rubinfeld, D.L.\n",
      "\n",
      "This is a copy of UCI ML housing dataset.\n",
      "http://archive.ics.uci.edu/ml/datasets/Housing\n",
      "\n",
      "\n",
      "This dataset was taken from the StatLib library which is maintained at Carnegie Mellon University.\n",
      "\n",
      "The Boston house-price data of Harrison, D. and Rubinfeld, D.L. 'Hedonic\n",
      "prices and the demand for clean air', J. Environ. Economics & Management,\n",
      "vol.5, 81-102, 1978.   Used in Belsley, Kuh & Welsch, 'Regression diagnostics\n",
      "...', Wiley, 1980.   N.B. Various transformations are used in the table on\n",
      "pages 244-261 of the latter.\n",
      "\n",
      "The Boston house-price data has been used in many machine learning papers that address regression\n",
      "problems.   \n",
      "     \n",
      "**References**\n",
      "\n",
      "   - Belsley, Kuh & Welsch, 'Regression diagnostics: Identifying Influential Data and Sources of Collinearity', Wiley, 1980. 244-261.\n",
      "   - Quinlan,R. (1993). Combining Instance-Based and Model-Based Learning. In Proceedings on the Tenth International Conference of Machine Learning, 236-243, University of Massachusetts, Amherst. Morgan Kaufmann.\n",
      "   - many more! (see http://archive.ics.uci.edu/ml/datasets/Housing)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To get a description of the data we can run the following\n",
    "print(boston.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with let's perform a very simple regression on two variables. For this i am going to choose 'RM' vs 'PRICE' as these should be directly correlated. i.e the more rooms the house has the higher its value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'plotly'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-88-d324926e6a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;31m#an account as it is hosted in the cloud.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m#import plotly.plotly as plt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m py.tools.set_credentials_file(username='j.carpenter_12', \n\u001b[1;32m      8\u001b[0m                               api_key='nFGzoPt30albxesyjGOJ')\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'plotly'"
     ]
    }
   ],
   "source": [
    "#Plotting the data to look for a linear relationship\n",
    "\n",
    "#Here i am using the library plotly to visualise the data. This package requires\n",
    "#an account as it is hosted in the cloud. \n",
    "#import plotly.plotly as plt\n",
    "import plotly as py\n",
    "py.tools.set_credentials_file(username='j.carpenter_12', \n",
    "                              api_key='nFGzoPt30albxesyjGOJ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "From the above we can see that in general as the number of rooms increases so does the value of the house. Implying a linear relationship between the two variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.067815</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.314815</td>\n",
       "      <td>0.577505</td>\n",
       "      <td>0.641607</td>\n",
       "      <td>0.269203</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.208015</td>\n",
       "      <td>0.287234</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.089680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.242302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.547998</td>\n",
       "      <td>0.782698</td>\n",
       "      <td>0.348962</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.104962</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.204470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000236</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.242302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.172840</td>\n",
       "      <td>0.694386</td>\n",
       "      <td>0.599382</td>\n",
       "      <td>0.348962</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.104962</td>\n",
       "      <td>0.553191</td>\n",
       "      <td>0.989737</td>\n",
       "      <td>0.063466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.063050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.658555</td>\n",
       "      <td>0.441813</td>\n",
       "      <td>0.448545</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.066794</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>0.994276</td>\n",
       "      <td>0.033389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.063050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150206</td>\n",
       "      <td>0.687105</td>\n",
       "      <td>0.528321</td>\n",
       "      <td>0.448545</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>0.066794</td>\n",
       "      <td>0.648936</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099338</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       CRIM    ZN     INDUS  CHAS       NOX        RM       AGE       DIS  \\\n",
       "0  0.000000  0.18  0.067815   0.0  0.314815  0.577505  0.641607  0.269203   \n",
       "1  0.000236  0.00  0.242302   0.0  0.172840  0.547998  0.782698  0.348962   \n",
       "2  0.000236  0.00  0.242302   0.0  0.172840  0.694386  0.599382  0.348962   \n",
       "3  0.000293  0.00  0.063050   0.0  0.150206  0.658555  0.441813  0.448545   \n",
       "4  0.000705  0.00  0.063050   0.0  0.150206  0.687105  0.528321  0.448545   \n",
       "\n",
       "        RAD       TAX   PTRATIO         B     LSTAT  \n",
       "0  0.000000  0.208015  0.287234  1.000000  0.089680  \n",
       "1  0.043478  0.104962  0.553191  1.000000  0.204470  \n",
       "2  0.043478  0.104962  0.553191  0.989737  0.063466  \n",
       "3  0.086957  0.066794  0.648936  0.994276  0.033389  \n",
       "4  0.086957  0.066794  0.648936  1.000000  0.099338  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Normalising the boston dataframe. \n",
    "#The purpose of this is to reduce all variables to the same scale\n",
    "from sklearn import preprocessing\n",
    "bos_new = bos\n",
    "del bos_new['PRICE'] #Drop price variable from normalisation\n",
    "val = bos_new.values\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "val_scaled = min_max_scaler.fit_transform(val)\n",
    "bos_norm = pd.DataFrame(val_scaled,columns=bos.columns)\n",
    "bos_norm.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have created our model we will need some to test it. This is where the idea of a training dataframe and a testing dataframe comes in. Train your model on one, test it on the other. Simple. \n",
    "\n",
    "As we only have one dataset of Boston housing data what we can do is use a sci-kitlearn package to randomly split the data into two\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X= pd.DataFrame(bos_norm['RM'],columns=['RM'])\n",
    "y= target #This is the price column\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our training data let's fit our model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "lr = linear_model.LinearRegression() \n",
    "lr.fit(X_train,y_train) #Fit the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>23.740350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>26.795459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>19.872333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>20.604844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>22.677315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>22.516520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.8</td>\n",
       "      <td>19.255951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>21.578548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.6</td>\n",
       "      <td>22.069867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.8</td>\n",
       "      <td>20.265388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.5</td>\n",
       "      <td>19.586474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.9</td>\n",
       "      <td>20.059927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>6.794324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21.2</td>\n",
       "      <td>22.096666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.5</td>\n",
       "      <td>17.415739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29.8</td>\n",
       "      <td>28.778600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.943294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.2</td>\n",
       "      <td>10.019161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50.0</td>\n",
       "      <td>36.773694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14.1</td>\n",
       "      <td>21.676812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Predicted\n",
       "0     23.6  23.740350\n",
       "1     32.4  26.795459\n",
       "2     13.6  19.872333\n",
       "3     22.8  20.604844\n",
       "4     16.1  22.677315\n",
       "5     20.0  22.516520\n",
       "6     17.8  19.255951\n",
       "7     14.0  21.578548\n",
       "8     19.6  22.069867\n",
       "9     16.8  20.265388\n",
       "10    21.5  19.586474\n",
       "11    18.9  20.059927\n",
       "12     7.0   6.794324\n",
       "13    21.2  22.096666\n",
       "14    18.5  17.415739\n",
       "15    29.8  28.778600\n",
       "16    18.8  18.943294\n",
       "17    10.2  10.019161\n",
       "18    50.0  36.773694\n",
       "19    14.1  21.676812"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict price on test data\n",
    "predicted = lr.predict(X_test)\n",
    "lr_predictions = pd.DataFrame({'Actual':y_test,'Predicted':predicted})\n",
    "lr_predictions[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see that at certain points the model is quite close to the actual values but sometimes quite far off. We can get the score and mean square error for our model as follows:\n",
    "\n",
    "'The Mean Squared Error (MSE) is a measure of how close a fitted line is to data points. For every data point, you take the distance vertically from the point to the corresponding y value on the curve fit (the error), and square the value. Then you add up all those values for all data points, and, in the case of a linear fit, divide by the number of points minus two.** The squaring is done so negative values do not cancel positive values. The smaller the Mean Squared Error, the closer the fit is to the data. The MSE has the units squared of whatever is plotted on the vertical axis.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.594613\n",
      "Mean Squared Error: 26.473346\n"
     ]
    }
   ],
   "source": [
    "#Actual vs predicted score\n",
    "score = lr.score(X_test,y_test)\n",
    "#Mean squared error\n",
    "mseFull = np.mean((y_test - lr.predict(X_test))**2)\n",
    "\n",
    "print(\"Accuracy of model: %f\" % score)\n",
    "print(\"Mean Squared Error: %f\" % mseFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see our model only has an accuracy of 38%, not great. We are only using one variable to predict Price out of a possible 13 to predict the Price. In the next section we will look at using multiple variables in a linear regression in an effort to improve the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multiple linear regression is used to predict a target variable Y using two or more independent variables X1,X2,X3..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we have already created a normalised dataset of the entire boston set we can just reuse that here to create our training data for multiple variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X= bos_norm\n",
    "y= target #This is the price column\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.15,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlr = linear_model.LinearRegression() \n",
    "mlr.fit(X_train,y_train) #Fit the model on the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>29.434253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>36.135564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>14.300537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>24.865454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>18.936624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>23.336226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.8</td>\n",
       "      <td>17.561542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>13.639191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.6</td>\n",
       "      <td>23.769703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.8</td>\n",
       "      <td>20.669951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.5</td>\n",
       "      <td>24.981433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.9</td>\n",
       "      <td>18.640734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>-5.384683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21.2</td>\n",
       "      <td>21.539508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.5</td>\n",
       "      <td>19.559598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29.8</td>\n",
       "      <td>26.199437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.8</td>\n",
       "      <td>20.720823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.2</td>\n",
       "      <td>6.428497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50.0</td>\n",
       "      <td>40.540828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14.1</td>\n",
       "      <td>17.840150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Predicted\n",
       "0     23.6  29.434253\n",
       "1     32.4  36.135564\n",
       "2     13.6  14.300537\n",
       "3     22.8  24.865454\n",
       "4     16.1  18.936624\n",
       "5     20.0  23.336226\n",
       "6     17.8  17.561542\n",
       "7     14.0  13.639191\n",
       "8     19.6  23.769703\n",
       "9     16.8  20.669951\n",
       "10    21.5  24.981433\n",
       "11    18.9  18.640734\n",
       "12     7.0  -5.384683\n",
       "13    21.2  21.539508\n",
       "14    18.5  19.559598\n",
       "15    29.8  26.199437\n",
       "16    18.8  20.720823\n",
       "17    10.2   6.428497\n",
       "18    50.0  40.540828\n",
       "19    14.1  17.840150"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predict price on test data \n",
    "predicted = mlr.predict(X_test)\n",
    "mlr_predictions = pd.DataFrame({'Actual':y_test,'Predicted':predicted})\n",
    "mlr_predictions[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.789701\n",
      "Mean Squared Error: 13.733307\n"
     ]
    }
   ],
   "source": [
    "#Actual vs predicted score\n",
    "score = mlr.score(X_test,y_test)\n",
    "#Mean squared error\n",
    "mseFull = np.mean((y_test - mlr.predict(X_test))**2)\n",
    "\n",
    "print(\"Accuracy of model: %f\" % score)\n",
    "print(\"Mean Squared Error: %f\" % mseFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see by adding multiple variables to our model we have almost doubled the accuracy. In the next section we will look at analysing the independent variables further to see if we can improve the model by removing certain ones from it, as so far we have only used one or all of them in the predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning and statistics, feature selection, also known as variable selection, attribute selection or variable subset selection, is the process of selecting a subset of relevant features (variables, predictors) for use in model construction.\n",
    "\n",
    "The central premise when using a feature selection technique is that the data contains many features that are either redundant or irrelevant, and can thus be removed without incurring much loss of information. Redundant or irrelevant features are two distinct notions, since one relevant feature may be redundant in the presence of another relevant feature with which it is strongly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel \n",
    "\n",
    "# This will throw out any variables that fall below this threshold\n",
    "sfm = SelectFromModel(lr,threshold=0.10) \n",
    "sfm.fit(X_test,y_test)\n",
    "n_features = sfm.transform(X_test).shape[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSE</th>\n",
       "      <th>n_features</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.636478</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21.903709</td>\n",
       "      <td>2</td>\n",
       "      <td>0.664588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.159241</td>\n",
       "      <td>3</td>\n",
       "      <td>0.767866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.368996</td>\n",
       "      <td>4</td>\n",
       "      <td>0.779967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12.359029</td>\n",
       "      <td>5</td>\n",
       "      <td>0.810746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>9.312791</td>\n",
       "      <td>6</td>\n",
       "      <td>0.857393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>9.276388</td>\n",
       "      <td>7</td>\n",
       "      <td>0.857950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.501195</td>\n",
       "      <td>8</td>\n",
       "      <td>0.869821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.124666</td>\n",
       "      <td>9</td>\n",
       "      <td>0.875587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>8.017986</td>\n",
       "      <td>10</td>\n",
       "      <td>0.877220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7.800633</td>\n",
       "      <td>11</td>\n",
       "      <td>0.880549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.783062</td>\n",
       "      <td>12</td>\n",
       "      <td>0.880818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.768804</td>\n",
       "      <td>13</td>\n",
       "      <td>0.881036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          MSE  n_features     score\n",
       "0   25.636478           1  0.607428\n",
       "1   21.903709           2  0.664588\n",
       "2   15.159241           3  0.767866\n",
       "3   14.368996           4  0.779967\n",
       "4   12.359029           5  0.810746\n",
       "5    9.312791           6  0.857393\n",
       "6    9.276388           7  0.857950\n",
       "7    8.501195           8  0.869821\n",
       "8    8.124666           9  0.875587\n",
       "9    8.017986          10  0.877220\n",
       "10   7.800633          11  0.880549\n",
       "11   7.783062          12  0.880818\n",
       "12   7.768804          13  0.881036"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = pd.DataFrame({'n_features':n_features,'score':score,'MSE':mseFull},index=[0])\n",
    "while n_features > 1:\n",
    "    sfm.threshold += 0.1\n",
    "    X_transform = sfm.transform(X_test)\n",
    "    n_features = X_transform.shape[1]\n",
    "    lr.fit(X_transform,y_test)\n",
    "    score = lr.score(X_transform,y_test)\n",
    "    mseFull = np.mean((y_test - lr.predict(X_transform))**2)\n",
    "    temp = pd.DataFrame({'n_features':n_features,'score':score,'MSE':mseFull},index=[0])\n",
    "    features = features.append(temp)\n",
    "    \n",
    "\n",
    "group_features = features.groupby(features['n_features'],as_index=False).last()\n",
    "group_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I won't go into too much detail about the above but essentially what the while loop is doing is fitting a linear regression with variables of increasing importance on Y. As you can see from the table however we can see that the more variables we have the better the score and so there is no need to remove certain ones to improve our model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Learning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision tree algorithims are used in a similar way to linear regression with the end goal to predict a target variable based off of the input of several other variables. Decision Trees are much better at predicting non-linear relationships and are also adaptable (classification or regression).\n",
    "\n",
    "Decision trees are classed as a supervised learning algorithim and work by spliting nodes(independent variables) into subsets on the most significant input variable. Below is a diagram of a titanic decision tree classification. We will be using the regressor not the classification because the target variable we are trying to predict is continuous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWgAAAFUCAMAAAA+g1YxAAAACXBIWXMAAAsTAAALEwEAmpwYAAAA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\naDoBgAAaDWg6AYAAGg1oOgGAAAMAmflvOK9Yn5AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image #Use this to import images into jupyter\n",
    "Image(\"images/titanic.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Divide & evaluate:\n",
    "\n",
    "  - split into subsets\n",
    "  - are they pure? (all yes or all no)\n",
    "  - if yes: stop (i.e if only males died on the titanic the decision tree would     stop on that as the only necessary information would be gender)\n",
    "  - if no: repeat (As this is obviously not the case the algorithim then goes on                    to other variables to evalulate, adding into its model that                      anyone who is male is 64% likely to have died)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading pydot-1.2.3.tar.gz\n",
      "Requirement already satisfied: pyparsing>=2.1.4 in c:\\python27\\lib\\site-packages (from pydot)\n",
      "Installing collected packages: pydot\n",
      "  Running setup.py install for pydot: started\n",
      "    Running setup.py install for pydot: finished with status 'done'\n",
      "Successfully installed pydot-1.2.3\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pydot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-124-2196d8e16549>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tree.dot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'pip install pydot'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mpydot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdotfile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport_graphviz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdotfile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pydot'"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import export_graphviz\n",
    "export_graphviz(dtr,out_file='tree.dot') \n",
    "!pip install pydot\n",
    "import pydot\n",
    "dotfile = StringIO()\n",
    "tree.export_graphviz(dtr, out_file=dotfile)\n",
    "pydot.graph_from_dot_data(dotfile.getvalue()).write_png(\"dtree2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>21.070896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>30.050000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>16.823810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>23.908571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>16.823810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20.0</td>\n",
       "      <td>21.070896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>17.8</td>\n",
       "      <td>18.589474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>14.455556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>19.6</td>\n",
       "      <td>21.070896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>16.8</td>\n",
       "      <td>21.070896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.5</td>\n",
       "      <td>18.589474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>18.9</td>\n",
       "      <td>18.589474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.0</td>\n",
       "      <td>9.959524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>21.2</td>\n",
       "      <td>21.070896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>18.5</td>\n",
       "      <td>21.070896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>29.8</td>\n",
       "      <td>23.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.8</td>\n",
       "      <td>18.589474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>10.2</td>\n",
       "      <td>9.959524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>50.0</td>\n",
       "      <td>42.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>14.1</td>\n",
       "      <td>14.230000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Actual  Predicted\n",
       "0     23.6  21.070896\n",
       "1     32.4  30.050000\n",
       "2     13.6  16.823810\n",
       "3     22.8  23.908571\n",
       "4     16.1  16.823810\n",
       "5     20.0  21.070896\n",
       "6     17.8  18.589474\n",
       "7     14.0  14.455556\n",
       "8     19.6  21.070896\n",
       "9     16.8  21.070896\n",
       "10    21.5  18.589474\n",
       "11    18.9  18.589474\n",
       "12     7.0   9.959524\n",
       "13    21.2  21.070896\n",
       "14    18.5  21.070896\n",
       "15    29.8  23.320000\n",
       "16    18.8  18.589474\n",
       "17    10.2   9.959524\n",
       "18    50.0  42.320000\n",
       "19    14.1  14.230000"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#As we are predicting a continuous variable, we import the regressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dtr = DecisionTreeRegressor(random_state = 100,\n",
    "                            max_depth=5, min_samples_leaf=5)\n",
    "\n",
    "#I have set the above max_depth here to account for every variable\n",
    "\n",
    "\n",
    "dtr.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predicted = dtr.predict(X_test)\n",
    "\n",
    "dtr_predictions = pd.DataFrame({'Actual':y_test,'Predicted':predicted})\n",
    "\n",
    "dtr_predictions[:20]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of model: 0.864029\n",
      "Mean Squared Error: 8.879419\n"
     ]
    }
   ],
   "source": [
    "#Model score \n",
    "score = dtr.score(X_test,y_test)\n",
    "mseFull = np.mean((y_test - predicted)**2)\n",
    "\n",
    "print(\"Accuracy of model: %f\" % score)\n",
    "print(\"Mean Squared Error: %f\" % mseFull)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see that a decision tree has done considerably better than both types of linear regression. This is without 'tuning' the model. Decision trees have many different hyper parameters one can set when using them but trying to improve the model by trial and error would take time. This is where grid search and cross validation come in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search & Cross Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid Search in its simplest terms is used to run a model repeatedly each time with differing parameters specified by the user. Cross validation is used to subset the data to create a test in order to evaluate each of these with a score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8167652691302683\n",
      "Best parameters: {'max_depth': 6, 'min_samples_leaf': 3}\n",
      "predicted score against actual: 0.898348\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>20.844961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>31.291667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>16.823810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>23.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>16.823810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0    23.6  20.844961\n",
       "1    32.4  31.291667\n",
       "2    13.6  16.823810\n",
       "3    22.8  23.542857\n",
       "4    16.1  16.823810"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params ={'max_depth':[1,2,3,4,5,6,7,8],\n",
    "         'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10]\n",
    "         }\n",
    "grid_search = GridSearchCV(dtr,param_grid=params,cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "\n",
    "predicted = grid_search.predict(X_test)\n",
    "\n",
    "grid_predictions = pd.DataFrame({'Actual':y_test,'Predicted':predicted})\n",
    "score = grid_search.score(X_test,y_test)\n",
    "print(\"predicted score against actual: %f\" % score)\n",
    "grid_predictions.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here i have only varied both the max_depth and min_samples_leaf but already we can see that the model's accuracy has increased by 3%. There are many more parameters you could vary with grid search but it is worth noting that the more parameter variation you have the longer it will take to run as it will run every combination "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Random Forest as the name suggests is a collection of decision trees. It randomly subsets the data and feeds it into decision trees. This is particularly useful as decision trees are prone to overfitting (overfitting is an issue where the model is too closely matched on the training data and consequently gives bad predictions on the test data as it is not general enough).A random forest reduces this by running each decision tree on different subset of the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted score against actual: 0.848783\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>23.142567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>28.093789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>15.516161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>24.002485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>15.412454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0    23.6  23.142567\n",
       "1    32.4  28.093789\n",
       "2    13.6  15.516161\n",
       "3    22.8  24.002485\n",
       "4    16.1  15.412454"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf = RandomForestRegressor(n_estimators= 250, random_state = 100,oob_score=True\n",
    "                               max_depth=3, min_samples_leaf=5,n_jobs=-1)\n",
    "\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "predicted = rf.predict(X_test)\n",
    "rf_predictions = pd.DataFrame({'Actual':y_test,'Predicted':predicted})\n",
    "rf_score = rf.score(X_test,y_test)\n",
    "print(\"predicted score against actual: %f\" % rf_score)\n",
    "rf_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grid search on random forest to tune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8249648203806896\n",
      "Best parameters: {'max_depth': 12, 'min_samples_leaf': 3, 'n_estimators': 140}\n",
      "predicted score against actual: 0.893745\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>22.997190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>30.823742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>16.529123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>23.245938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>16.978538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0    23.6  22.997190\n",
       "1    32.4  30.823742\n",
       "2    13.6  16.529123\n",
       "3    22.8  23.245938\n",
       "4    16.1  16.978538"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params ={'n_estimators':[130,140,150],'max_depth':[10,11,12,13],\n",
    "         'min_samples_leaf':[3,4,5,6]\n",
    "         }\n",
    "grid_search = GridSearchCV(rf,param_grid=params)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "\n",
    "predicted = grid_search.predict(X_test)\n",
    "\n",
    "grid_predictions = pd.DataFrame({'Actual':y_test,'Predicted':predicted})\n",
    "score = grid_search.score(X_test,y_test)\n",
    "print(\"predicted score against actual: %f\" % score)\n",
    "grid_predictions.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above we can see that the random forest actually scores slightly lower on the test data, but scores higher on the grid_search score. The reason for this might be that the test data we are using just happens to fit that model better than the random forest and might be different for other data as the subset we are using is fairly small for testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient boosted regression functions in a similar way to a random forest. The main difference between these are that a gradient boosted regression starts with a rough prediction and with each tree in the series after it trying to correct the prediction error. So for example at any instant t, the model outcomes are weighed based on the outcomes of previous isntant t-1. The outcomes predicted correctly are given a lower weight."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GBM parameters can generally be though of as \n",
    " - Tree-Specific Parameters: These affect each individual tree in the model\n",
    " - Boosting Parameters: These affect the boosting operation of the model\n",
    " - Misc Parameters: Other parameters for overall functioning\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted score against actual: 0.898410\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>23.116148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>29.078630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>16.753154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>23.278058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>16.734608</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0    23.6  23.116148\n",
       "1    32.4  29.078630\n",
       "2    13.6  16.753154\n",
       "3    22.8  23.278058\n",
       "4    16.1  16.734608"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "gbr = GradientBoostingRegressor(n_estimators= 15, random_state = 100,\n",
    "                               max_depth=3, min_samples_leaf=5,learning_rate=0.2)\n",
    "\n",
    "\n",
    "gbr.fit(X_train, y_train)\n",
    "predicted = gbr.predict(X_test)\n",
    "gbr_predictions = pd.DataFrame({'Actual':y_test,'Predicted':predicted})\n",
    "gbr_score = gbr.score(X_test,y_test)\n",
    "print(\"predicted score against actual: %f\" % gbr_score)\n",
    "gbr_predictions.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.8522559570386447\n",
      "Best parameters: {'learning_rate': 0.1, 'max_depth': 5, 'min_samples_split': 50, 'n_estimators': 70}\n",
      "predicted score against actual: 0.932982\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Actual</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23.6</td>\n",
       "      <td>24.338496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32.4</td>\n",
       "      <td>31.228680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.6</td>\n",
       "      <td>16.286739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22.8</td>\n",
       "      <td>22.305120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16.1</td>\n",
       "      <td>17.061458</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Actual  Predicted\n",
       "0    23.6  24.338496\n",
       "1    32.4  31.228680\n",
       "2    13.6  16.286739\n",
       "3    22.8  22.305120\n",
       "4    16.1  17.061458"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params ={'max_depth':range(1,10,2),\n",
    "         'min_samples_split':range(50,200,50),\n",
    "         'n_estimators':range(50,80,10),\n",
    "         'learning_rate':[0.1,0.05]\n",
    "         }\n",
    "grid_search = GridSearchCV(gbr,param_grid=params)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Best score: {}'.format(grid_search.best_score_))\n",
    "print('Best parameters: {}'.format(grid_search.best_params_))\n",
    "\n",
    "predicted = grid_search.predict(X_test)\n",
    "\n",
    "grid_predictions = pd.DataFrame({'Actual':y_test,'Predicted':predicted})\n",
    "score = grid_search.score(X_test,y_test)\n",
    "print(\"predicted score against actual: %f\" % score)\n",
    "grid_predictions.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the scores we can see that the gradient boosted model by far performs the best, scoring a 93% accuracy rating on its predictions. I have spent some time tuning this model but as always I am sure that finer tuning could be applied to improve it further. With these decision tree algorithims it always helps to read up on them as much as possible as the better you understand how they work the better you will be able to use them. I will include some links below that I have found particularly useful when putting this together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
